{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "      <th>words</th>\n",
       "      <th>sentences</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>average_word_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['well', 'right', 'now', 'i', 'just', 'woke', ...</td>\n",
       "      <td>['well, right now i just woke up from a mid-da...</td>\n",
       "      <td>[('well', 'right'), ('right', 'now'), ('now', ...</td>\n",
       "      <td>[('well', 'right', 'now'), ('right', 'now', 'i...</td>\n",
       "      <td>[ 1.46904569e-02  1.52049020e-01 -2.17639774e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['well', 'here', 'we', 'go', 'with', 'the', 's...</td>\n",
       "      <td>['well, here we go with the stream of consciou...</td>\n",
       "      <td>[('well', 'here'), ('here', 'we'), ('we', 'go'...</td>\n",
       "      <td>[('well', 'here', 'we'), ('here', 'we', 'go'),...</td>\n",
       "      <td>[ 1.93020366e-02  2.00337350e-01 -2.47012377e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['an', 'open', 'keyboard', 'and', 'buttons', '...</td>\n",
       "      <td>['an open keyboard and buttons to push.', 'the...</td>\n",
       "      <td>[('an', 'open'), ('open', 'keyboard'), ('keybo...</td>\n",
       "      <td>[('an', 'open', 'keyboard'), ('open', 'keyboar...</td>\n",
       "      <td>[ 1.21683925e-02  1.49960428e-01 -2.17856288e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['i', 'cant', 'believe', 'it', 'its', 'really'...</td>\n",
       "      <td>[\"i can't believe it!\", \"it's really happening...</td>\n",
       "      <td>[('i', 'cant'), ('cant', 'believe'), ('believe...</td>\n",
       "      <td>[('i', 'cant', 'believe'), ('cant', 'believe',...</td>\n",
       "      <td>[-1.21900747e-02  1.94802403e-01 -2.04183444e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['well', 'here', 'i', 'go', 'with', 'the', 'go...</td>\n",
       "      <td>['well, here i go with the good old stream of ...</td>\n",
       "      <td>[('well', 'here'), ('here', 'i'), ('i', 'go'),...</td>\n",
       "      <td>[('well', 'here', 'i'), ('here', 'i', 'go'), (...</td>\n",
       "      <td>[-6.53621508e-03  1.72239631e-01 -2.12745324e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  cEXT  cNEU  cAGR  cCON  \\\n",
       "0  Well, right now I just woke up from a mid-day ...     0     1     1     0   \n",
       "1  Well, here we go with the stream of consciousn...     0     0     1     0   \n",
       "2  An open keyboard and buttons to push. The thin...     0     1     0     1   \n",
       "3  I can't believe it!  It's really happening!  M...     1     0     1     1   \n",
       "4  Well, here I go with the good old stream of co...     1     0     1     0   \n",
       "\n",
       "   cOPN                                              words  \\\n",
       "0     1  ['well', 'right', 'now', 'i', 'just', 'woke', ...   \n",
       "1     0  ['well', 'here', 'we', 'go', 'with', 'the', 's...   \n",
       "2     1  ['an', 'open', 'keyboard', 'and', 'buttons', '...   \n",
       "3     0  ['i', 'cant', 'believe', 'it', 'its', 'really'...   \n",
       "4     1  ['well', 'here', 'i', 'go', 'with', 'the', 'go...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  ['well, right now i just woke up from a mid-da...   \n",
       "1  ['well, here we go with the stream of consciou...   \n",
       "2  ['an open keyboard and buttons to push.', 'the...   \n",
       "3  [\"i can't believe it!\", \"it's really happening...   \n",
       "4  ['well, here i go with the good old stream of ...   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [('well', 'right'), ('right', 'now'), ('now', ...   \n",
       "1  [('well', 'here'), ('here', 'we'), ('we', 'go'...   \n",
       "2  [('an', 'open'), ('open', 'keyboard'), ('keybo...   \n",
       "3  [('i', 'cant'), ('cant', 'believe'), ('believe...   \n",
       "4  [('well', 'here'), ('here', 'i'), ('i', 'go'),...   \n",
       "\n",
       "                                            trigrams  \\\n",
       "0  [('well', 'right', 'now'), ('right', 'now', 'i...   \n",
       "1  [('well', 'here', 'we'), ('here', 'we', 'go'),...   \n",
       "2  [('an', 'open', 'keyboard'), ('open', 'keyboar...   \n",
       "3  [('i', 'cant', 'believe'), ('cant', 'believe',...   \n",
       "4  [('well', 'here', 'i'), ('here', 'i', 'go'), (...   \n",
       "\n",
       "                              average_word_embedding  \n",
       "0  [ 1.46904569e-02  1.52049020e-01 -2.17639774e-...  \n",
       "1  [ 1.93020366e-02  2.00337350e-01 -2.47012377e-...  \n",
       "2  [ 1.21683925e-02  1.49960428e-01 -2.17856288e-...  \n",
       "3  [-1.21900747e-02  1.94802403e-01 -2.04183444e-...  \n",
       "4  [-6.53621508e-03  1.72239631e-01 -2.12745324e-...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "essays=pd.read_csv(\"../data/essays_expanded.csv\")\n",
    "\n",
    "essays.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline classifier: random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_random_classifier(df_test, personality):\n",
    "\n",
    "    y_test = df_test[[personality]]\n",
    "    y_pred = np.random.randint(2, size=len(y_test))\n",
    "    print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "    return f1_score(y_pred=y_pred, y_true=y_test, average=\"macro\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR and SVM training and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr(df_train, vectorizer, personality, lr_kwargs={\"max_iter\": 1000, \"solver\": \"liblinear\"}):\n",
    "    \"\"\"\n",
    "    Receives the train set `df_train` as pd.DataFrame and extracts lemma n-grams\n",
    "    with their correspoding labels (news type).\n",
    "    The text is vectorized and used to train a logistic regression with\n",
    "    training arguments passed as `lr_kwargs`.\n",
    "    Returns the fitted model.\n",
    "    \"\"\"\n",
    "    vectorizer.set_params(max_df=df_train.shape[0])\n",
    "    X=vectorizer.fit_transform(df_train.TEXT)\n",
    "    model=LR(**lr_kwargs)\n",
    "    model.fit(X, df_train[[personality]])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_svm(df_train, vectorizer, personality):\n",
    "    \"\"\"\n",
    "    Receives the train set `df_train` as pd.DataFrame and extracts lemma n-grams\n",
    "    with their correspoding labels (news type).\n",
    "    The text is vectorized and used to train a logistic regression with\n",
    "    training arguments passed as `lr_kwargs`.\n",
    "    Returns the fitted model.\n",
    "    \"\"\"\n",
    "    vectorizer.set_params(max_df=df_train.shape[0])\n",
    "    X=vectorizer.fit_transform(df_train.TEXT)\n",
    "    model=SVC(kernel=\"linear\")\n",
    "    model.fit(X, df_train[[personality]])\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_performance(model, df_test, vectorizer, personality):\n",
    "\n",
    "    X_test, y_test = df_test.TEXT, df_test[[personality]]\n",
    "    X_vec = vectorizer.transform(X_test)\n",
    "    y_pred = model.predict(X_vec)\n",
    "    print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "    return f1_score(y_pred=y_pred, y_true=y_test, average=\"macro\")\n",
    "\n",
    "\n",
    "def influential_ngrams(model, vectorizer, is_lr=True):\n",
    "    \"\"\"\n",
    "    Receives a model (LR or SVM) and a vectorizer.\n",
    "    Prints the most influential n-grams.\n",
    "    \"\"\"\n",
    "\n",
    "    if is_lr:\n",
    "        print(\"Logistic regression\\n\")\n",
    "        print(\"The most influential n-grams for classification 1 are:\")\n",
    "        ind = np.argsort(model.coef_)[0][-10:]\n",
    "        for index in ind:\n",
    "            print(vectorizer.get_feature_names()[index])\n",
    "\n",
    "\n",
    "        print(\"The most influential n-grams for classification 0 are:\")\n",
    "        ind = np.argsort(model.coef_)[0][:10]\n",
    "        for index in ind:\n",
    "            print(vectorizer.get_feature_names()[index])\n",
    "\n",
    "    else:\n",
    "        print(\"SVM\\n\")\n",
    "        print(\"The most influential n-grams for classification 1 are:\")\n",
    "        ind = np.argsort(svm.coef_.toarray())[0][-10:]\n",
    "        for index in ind:\n",
    "            print(count_vectorizer.get_feature_names()[index])\n",
    "\n",
    "        print(\"The most influential n-grams for classification 0 are:\")\n",
    "        ind = np.argsort(svm.coef_.toarray())[0][:10]\n",
    "        for index in ind:\n",
    "            print(count_vectorizer.get_feature_names()[index])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Raw text n-grams\\\\\\\\\n",
    "The n-grams will be extracted out of the raw essay text and given to the models as features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_train, essays_test = train_test_split(\n",
    "    essays[[\"TEXT\", \"cEXT\", \"cOPN\", \"cAGR\", \"cCON\", \"cNEU\"]], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "count_vectorizer = CountVectorizer(lowercase=False, ngram_range=(1,3), analyzer=\"word\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.52      0.51       227\n",
      "           1       0.57      0.55      0.56       267\n",
      "\n",
      "    accuracy                           0.54       494\n",
      "   macro avg       0.54      0.54      0.54       494\n",
      "weighted avg       0.54      0.54      0.54       494\n",
      "\n",
      "f1 = 0.535\n"
     ]
    }
   ],
   "source": [
    "f1=baseline_random_classifier(essays_test, \"cEXT\")\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.62      0.57       237\n",
      "           1       0.58      0.49      0.53       257\n",
      "\n",
      "    accuracy                           0.55       494\n",
      "   macro avg       0.56      0.56      0.55       494\n",
      "weighted avg       0.56      0.55      0.55       494\n",
      "\n",
      "f1 = 0.552\n"
     ]
    }
   ],
   "source": [
    "f1=baseline_random_classifier(essays_test, \"cOPN\")\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.53      0.50       220\n",
      "           1       0.57      0.51      0.54       274\n",
      "\n",
      "    accuracy                           0.52       494\n",
      "   macro avg       0.52      0.52      0.52       494\n",
      "weighted avg       0.53      0.52      0.52       494\n",
      "\n",
      "f1 = 0.517\n"
     ]
    }
   ],
   "source": [
    "f1=baseline_random_classifier(essays_test, \"cAGR\")\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.46      0.44       227\n",
      "           1       0.51      0.49      0.50       267\n",
      "\n",
      "    accuracy                           0.47       494\n",
      "   macro avg       0.47      0.47      0.47       494\n",
      "weighted avg       0.48      0.47      0.47       494\n",
      "\n",
      "f1 = 0.472\n"
     ]
    }
   ],
   "source": [
    "f1=baseline_random_classifier(essays_test, \"cCON\")\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.42      0.44       260\n",
      "           1       0.42      0.47      0.45       234\n",
      "\n",
      "    accuracy                           0.45       494\n",
      "   macro avg       0.45      0.45      0.45       494\n",
      "weighted avg       0.45      0.45      0.45       494\n",
      "\n",
      "f1 = 0.445\n"
     ]
    }
   ],
   "source": [
    "f1=baseline_random_classifier(essays_test, \"cNEU\")\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jurin\\anaconda3\\envs\\tarlab1\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.53      0.53       227\n",
      "           1       0.60      0.58      0.59       267\n",
      "\n",
      "    accuracy                           0.56       494\n",
      "   macro avg       0.56      0.56      0.56       494\n",
      "weighted avg       0.56      0.56      0.56       494\n",
      "\n",
      "f1 = 0.559\n"
     ]
    }
   ],
   "source": [
    "lr = train_lr(essays_train, count_vectorizer, \"cEXT\")\n",
    "f1 = test_performance(lr, essays_test, count_vectorizer, \"cEXT\")\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n",
      "\n",
      "The most influential n-grams for classification 1 are:\n",
      "some of\n",
      "many\n",
      "if\n",
      "college\n",
      "four\n",
      "love\n",
      "myself\n",
      "first\n",
      "boyfriend\n",
      "fun\n",
      "The most influential n-grams for classification 0 are:\n",
      "should\n",
      "real\n",
      "there\n",
      "could\n",
      "don\n",
      "few\n",
      "So\n",
      "eyes\n",
      "even though\n",
      "three\n"
     ]
    }
   ],
   "source": [
    "influential_ngrams(lr, count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.54      0.53       227\n",
      "           1       0.59      0.57      0.58       267\n",
      "\n",
      "    accuracy                           0.55       494\n",
      "   macro avg       0.55      0.55      0.55       494\n",
      "weighted avg       0.56      0.55      0.56       494\n",
      "\n",
      "f1 = 0.553\n"
     ]
    }
   ],
   "source": [
    "svm = train_svm(essays_train, count_vectorizer, \"cEXT\")\n",
    "f1 = test_performance(svm, essays_test, count_vectorizer, \"cEXT\")\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "\n",
      "The most influential n-grams for classification 1 are:\n",
      "if\n",
      "some of\n",
      "many\n",
      "college\n",
      "four\n",
      "first\n",
      "myself\n",
      "love\n",
      "boyfriend\n",
      "fun\n",
      "The most influential n-grams for classification 0 are:\n",
      "real\n",
      "should\n",
      "So\n",
      "could\n",
      "few\n",
      "there\n",
      "three\n",
      "don\n",
      "eyes\n",
      "even though\n"
     ]
    }
   ],
   "source": [
    "influential_ngrams(svm, count_vectorizer, is_lr=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Openness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.62      0.60       237\n",
      "           1       0.63      0.59      0.61       257\n",
      "\n",
      "    accuracy                           0.61       494\n",
      "   macro avg       0.61      0.61      0.61       494\n",
      "weighted avg       0.61      0.61      0.61       494\n",
      "\n",
      "f1 = 0.605\n"
     ]
    }
   ],
   "source": [
    "lr = train_lr(essays_train, count_vectorizer, \"cOPN\")\n",
    "f1 = test_performance(lr, essays_test, count_vectorizer, \"cOPN\")\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n",
      "\n",
      "The most influential n-grams for classification 1 are:\n",
      "myself\n",
      "now that\n",
      "my mom\n",
      "crazy\n",
      "re\n",
      "music\n",
      "is so\n",
      "to my\n",
      "great\n",
      "maybe\n",
      "The most influential n-grams for classification 0 are:\n",
      "college\n",
      "problem\n",
      "to do\n",
      "classes\n",
      "time to\n",
      "thinks\n",
      "Well\n",
      "assignment\n",
      "home\n",
      "tomorrow\n"
     ]
    }
   ],
   "source": [
    "influential_ngrams(lr, count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.59      0.58       237\n",
      "           1       0.61      0.59      0.60       257\n",
      "\n",
      "    accuracy                           0.59       494\n",
      "   macro avg       0.59      0.59      0.59       494\n",
      "weighted avg       0.59      0.59      0.59       494\n",
      "\n",
      "f1 = 0.593\n"
     ]
    }
   ],
   "source": [
    "svm = train_svm(essays_train, count_vectorizer, \"cOPN\")\n",
    "f1 = test_performance(svm, essays_test, count_vectorizer, \"cOPN\")\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "\n",
      "The most influential n-grams for classification 1 are:\n",
      "music\n",
      "re\n",
      "great\n",
      "love him\n",
      "crazy\n",
      "now that\n",
      "my mom\n",
      "is so\n",
      "to my\n",
      "maybe\n",
      "The most influential n-grams for classification 0 are:\n",
      "college\n",
      "problem\n",
      "to do\n",
      "thinks\n",
      "time to\n",
      "classes\n",
      "Well\n",
      "tomorrow\n",
      "confused\n",
      "assignment\n"
     ]
    }
   ],
   "source": [
    "influential_ngrams(svm, count_vectorizer, is_lr=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.44      0.44       220\n",
      "           1       0.56      0.57      0.56       274\n",
      "\n",
      "    accuracy                           0.51       494\n",
      "   macro avg       0.50      0.50      0.50       494\n",
      "weighted avg       0.51      0.51      0.51       494\n",
      "\n",
      "f1 = 0.503\n"
     ]
    }
   ],
   "source": [
    "lr = train_lr(essays_train, count_vectorizer, \"cAGR\")\n",
    "f1 = test_performance(lr, essays_test, count_vectorizer, \"cAGR\")\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n",
      "\n",
      "The most influential n-grams for classification 1 are:\n",
      "Well\n",
      "worried\n",
      "ok\n",
      "least\n",
      "have to\n",
      "my mind\n",
      "right\n",
      "and have\n",
      "family\n",
      "and the\n",
      "The most influential n-grams for classification 0 are:\n",
      "and it\n",
      "And\n",
      "think that\n",
      "stupid\n",
      "girlfriend\n",
      "read\n",
      "more\n",
      "same\n",
      "is no\n",
      "assignment\n"
     ]
    }
   ],
   "source": [
    "influential_ngrams(lr, count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.44      0.44       220\n",
      "           1       0.56      0.57      0.56       274\n",
      "\n",
      "    accuracy                           0.51       494\n",
      "   macro avg       0.50      0.50      0.50       494\n",
      "weighted avg       0.51      0.51      0.51       494\n",
      "\n",
      "f1 = 0.503\n"
     ]
    }
   ],
   "source": [
    "svm = train_svm(essays_train, count_vectorizer, \"cAGR\")\n",
    "f1 = test_performance(svm, essays_test, count_vectorizer, \"cAGR\")\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "\n",
      "The most influential n-grams for classification 1 are:\n",
      "sometimes\n",
      "worried\n",
      "right\n",
      "least\n",
      "have to\n",
      "my mind\n",
      "family\n",
      "ok\n",
      "and have\n",
      "and the\n",
      "The most influential n-grams for classification 0 are:\n",
      "and it\n",
      "And\n",
      "stupid\n",
      "think that\n",
      "sitting\n",
      "is no\n",
      "girlfriend\n",
      "store\n",
      "write about\n",
      "more\n"
     ]
    }
   ],
   "source": [
    "influential_ngrams(svm, count_vectorizer, is_lr=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conscientiousness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.55      0.53       227\n",
      "           1       0.60      0.58      0.59       267\n",
      "\n",
      "    accuracy                           0.56       494\n",
      "   macro avg       0.56      0.56      0.56       494\n",
      "weighted avg       0.56      0.56      0.56       494\n",
      "\n",
      "f1 = 0.561\n"
     ]
    }
   ],
   "source": [
    "lr = train_lr(essays_train, count_vectorizer, \"cCON\")\n",
    "f1 = test_performance(lr, essays_test, count_vectorizer, \"cCON\")\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n",
      "\n",
      "The most influential n-grams for classification 1 are:\n",
      "tonight\n",
      "everyone\n",
      "do not\n",
      "For\n",
      "party\n",
      "since\n",
      "we are\n",
      "of my\n",
      "couldn\n",
      "sometimes\n",
      "The most influential n-grams for classification 0 are:\n",
      "hate\n",
      "my friend\n",
      "is it\n",
      "you know\n",
      "because my\n",
      "not to\n",
      "want\n",
      "they re\n",
      "am in\n",
      "Austin\n"
     ]
    }
   ],
   "source": [
    "influential_ngrams(lr, count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.56      0.54       227\n",
      "           1       0.60      0.57      0.58       267\n",
      "\n",
      "    accuracy                           0.56       494\n",
      "   macro avg       0.56      0.56      0.56       494\n",
      "weighted avg       0.56      0.56      0.56       494\n",
      "\n",
      "f1 = 0.562\n"
     ]
    }
   ],
   "source": [
    "svm = train_svm(essays_train, count_vectorizer, \"cCON\")\n",
    "f1 = test_performance(svm, essays_test, count_vectorizer, \"cCON\")\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "\n",
      "The most influential n-grams for classification 1 are:\n",
      "week\n",
      "If\n",
      "do not\n",
      "since\n",
      "party\n",
      "of my\n",
      "For\n",
      "we are\n",
      "couldn\n",
      "sometimes\n",
      "The most influential n-grams for classification 0 are:\n",
      "hate\n",
      "my friend\n",
      "is it\n",
      "because my\n",
      "am in\n",
      "not to\n",
      "Austin\n",
      "you know\n",
      "Is\n",
      "they re\n"
     ]
    }
   ],
   "source": [
    "influential_ngrams(svm, count_vectorizer, is_lr=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuroticism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.60       260\n",
      "           1       0.57      0.63      0.60       234\n",
      "\n",
      "    accuracy                           0.60       494\n",
      "   macro avg       0.60      0.60      0.60       494\n",
      "weighted avg       0.60      0.60      0.60       494\n",
      "\n",
      "f1 = 0.599\n"
     ]
    }
   ],
   "source": [
    "lr = train_lr(essays_train, count_vectorizer, \"cNEU\")\n",
    "f1 = test_performance(lr, essays_test, count_vectorizer, \"cNEU\")\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n",
      "\n",
      "The most influential n-grams for classification 1 are:\n",
      "to visit\n",
      "everything\n",
      "being\n",
      "someone\n",
      "have to\n",
      "life\n",
      "money\n",
      "sex\n",
      "week\n",
      "stressed\n",
      "The most influential n-grams for classification 0 are:\n",
      "me and\n",
      "many\n",
      "in the\n",
      "for my\n",
      "it has\n",
      "already\n",
      "its\n",
      "semester\n",
      "would\n",
      "usually\n"
     ]
    }
   ],
   "source": [
    "influential_ngrams(lr, count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59       260\n",
      "           1       0.56      0.62      0.59       234\n",
      "\n",
      "    accuracy                           0.59       494\n",
      "   macro avg       0.59      0.59      0.59       494\n",
      "weighted avg       0.59      0.59      0.59       494\n",
      "\n",
      "f1 = 0.589\n"
     ]
    }
   ],
   "source": [
    "svm = train_svm(essays_train, count_vectorizer, \"cNEU\")\n",
    "f1 = test_performance(svm, essays_test, count_vectorizer, \"cNEU\")\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "\n",
      "The most influential n-grams for classification 1 are:\n",
      "worry\n",
      "quite\n",
      "someone\n",
      "have to\n",
      "to visit\n",
      "life\n",
      "money\n",
      "week\n",
      "sex\n",
      "stressed\n",
      "The most influential n-grams for classification 0 are:\n",
      "me and\n",
      "many\n",
      "for my\n",
      "it has\n",
      "in the\n",
      "already\n",
      "semester\n",
      "thing\n",
      "its\n",
      "usually\n"
     ]
    }
   ],
   "source": [
    "influential_ngrams(svm, count_vectorizer, is_lr=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tarlab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
